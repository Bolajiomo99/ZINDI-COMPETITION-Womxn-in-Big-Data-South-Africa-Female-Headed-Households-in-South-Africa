{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - IMPORTING THE NEEDED PYTHON MODULES AND DATA SETS INTO THE WORKSPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2822, 61)\n",
      "(1013, 60)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "\n",
    "train = pd.read_csv('train_copy.csv')\n",
    "test = pd.read_csv('test_copy.csv')\n",
    "test_ID = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - SPLITTING THE DATASET INTO X AND y FOR TRAINING OUR ML ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (2822, 60)\n",
      "Shape of y (2822,)\n",
      "Shape of ID (1013,)\n"
     ]
    }
   ],
   "source": [
    "# WE ARE DROPPING THE 'target' pd series(column) FROM X \n",
    "X = train.drop('target', axis=1)\n",
    "\n",
    "y = train['target']\n",
    "\n",
    "ID = test_ID['ward']\n",
    "\n",
    "print(\"Shape of X\", X.shape)\n",
    "print(\"Shape of y\", y.shape)\n",
    "print(\"Shape of ID\", ID.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - IMPORTING OUR MODELS (ML ALGORITHMS) I WANT TO TRAIN WITH THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from mlxtend.regressor import StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -LETS IMPLEMENT SOME FORM OF STACKING USING THE 'StackingRegressor' ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING THE ML ALGORITHMS WE WANT TO STACK TOGETHER\n",
    "CAT1 = CatBoostRegressor(metric_period=50)\n",
    "CAT2 = CatBoostRegressor(metric_period=20, eval_metric='RMSE')\n",
    "\n",
    "# CREATING A XGB ALGORITM TO SERVE AS OUT META-REGRESSOR (it aggregates prediction from the stacked models)\n",
    "XG = XGBRegressor()\n",
    "\n",
    "# CREATING PUT STACKED MODEL USING \"StackingRegressor\"\n",
    "model = StackingRegressor(regressors= [CAT1, CAT2], meta_regressor= XG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - TO MAKE THIS FANCY, I DEFINE A FUNCTION TO OUTPUT OUR PREDICTED VALUES INTO A CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_csv(file_name, algorithm = model, X_data = X, y_data= y, ID_column = ID, test_data = test):\n",
    "    algorithm.fit(X_data, y_data)\n",
    "\n",
    "    pred = algorithm.predict(test_data)\n",
    "    \n",
    "\n",
    "    output = pd.DataFrame({'ward' : ID_column,\n",
    "                           'target' : pred})\n",
    "\n",
    "    output.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - OKAY LET US GENERATE SOME PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 25.8472228\ttotal: 184ms\tremaining: 3m 3s\n",
      "50:\tlearn: 7.3618164\ttotal: 4.84s\tremaining: 1m 30s\n",
      "100:\tlearn: 4.0681476\ttotal: 9.38s\tremaining: 1m 23s\n",
      "150:\tlearn: 3.5402620\ttotal: 14.2s\tremaining: 1m 19s\n",
      "200:\tlearn: 3.3542655\ttotal: 18.7s\tremaining: 1m 14s\n",
      "250:\tlearn: 3.2601365\ttotal: 23.3s\tremaining: 1m 9s\n",
      "300:\tlearn: 3.1996060\ttotal: 26.8s\tremaining: 1m 2s\n",
      "350:\tlearn: 3.1395610\ttotal: 29.9s\tremaining: 55.2s\n",
      "400:\tlearn: 3.0599333\ttotal: 33.7s\tremaining: 50.3s\n",
      "450:\tlearn: 2.9953229\ttotal: 37.3s\tremaining: 45.4s\n",
      "500:\tlearn: 2.9477816\ttotal: 40.8s\tremaining: 40.7s\n",
      "550:\tlearn: 2.8853993\ttotal: 44.6s\tremaining: 36.3s\n",
      "600:\tlearn: 2.8262693\ttotal: 48.6s\tremaining: 32.3s\n",
      "650:\tlearn: 2.7778184\ttotal: 52.7s\tremaining: 28.2s\n",
      "700:\tlearn: 2.7226032\ttotal: 57.1s\tremaining: 24.3s\n",
      "750:\tlearn: 2.6731012\ttotal: 1m 1s\tremaining: 20.4s\n",
      "800:\tlearn: 2.6346432\ttotal: 1m 6s\tremaining: 16.4s\n",
      "850:\tlearn: 2.5950697\ttotal: 1m 10s\tremaining: 12.3s\n",
      "900:\tlearn: 2.5678463\ttotal: 1m 14s\tremaining: 8.16s\n",
      "950:\tlearn: 2.5342177\ttotal: 1m 19s\tremaining: 4.08s\n",
      "999:\tlearn: 2.5056389\ttotal: 1m 23s\tremaining: 0us\n",
      "0:\tlearn: 25.8472228\ttotal: 110ms\tremaining: 1m 49s\n",
      "20:\tlearn: 14.9378452\ttotal: 2.04s\tremaining: 1m 35s\n",
      "40:\tlearn: 9.1090804\ttotal: 3.87s\tremaining: 1m 30s\n",
      "60:\tlearn: 6.1191232\ttotal: 5.7s\tremaining: 1m 27s\n",
      "80:\tlearn: 4.7126589\ttotal: 7.51s\tremaining: 1m 25s\n",
      "100:\tlearn: 4.0681476\ttotal: 9.46s\tremaining: 1m 24s\n",
      "120:\tlearn: 3.7623602\ttotal: 11.5s\tremaining: 1m 23s\n",
      "140:\tlearn: 3.5971580\ttotal: 13.3s\tremaining: 1m 20s\n",
      "160:\tlearn: 3.4947965\ttotal: 15.1s\tremaining: 1m 18s\n",
      "180:\tlearn: 3.4091098\ttotal: 16.9s\tremaining: 1m 16s\n",
      "200:\tlearn: 3.3542655\ttotal: 18.7s\tremaining: 1m 14s\n",
      "220:\tlearn: 3.3123457\ttotal: 20.5s\tremaining: 1m 12s\n",
      "240:\tlearn: 3.2832494\ttotal: 22.3s\tremaining: 1m 10s\n",
      "260:\tlearn: 3.2494131\ttotal: 24s\tremaining: 1m 7s\n",
      "280:\tlearn: 3.2222634\ttotal: 25.7s\tremaining: 1m 5s\n",
      "300:\tlearn: 3.1996060\ttotal: 26.9s\tremaining: 1m 2s\n",
      "320:\tlearn: 3.1814762\ttotal: 28.1s\tremaining: 59.4s\n",
      "340:\tlearn: 3.1596984\ttotal: 29.2s\tremaining: 56.4s\n",
      "360:\tlearn: 3.1226306\ttotal: 30.7s\tremaining: 54.3s\n",
      "380:\tlearn: 3.0961905\ttotal: 31.9s\tremaining: 51.9s\n",
      "400:\tlearn: 3.0599333\ttotal: 33.6s\tremaining: 50.1s\n",
      "420:\tlearn: 3.0327441\ttotal: 35s\tremaining: 48.2s\n",
      "440:\tlearn: 3.0105092\ttotal: 36.5s\tremaining: 46.2s\n",
      "460:\tlearn: 2.9912323\ttotal: 37.7s\tremaining: 44.1s\n",
      "480:\tlearn: 2.9681051\ttotal: 39.3s\tremaining: 42.4s\n",
      "500:\tlearn: 2.9477816\ttotal: 40.8s\tremaining: 40.6s\n",
      "520:\tlearn: 2.9163798\ttotal: 42.6s\tremaining: 39.2s\n",
      "540:\tlearn: 2.8931518\ttotal: 44s\tremaining: 37.3s\n",
      "560:\tlearn: 2.8748041\ttotal: 45.5s\tremaining: 35.6s\n",
      "580:\tlearn: 2.8513825\ttotal: 47s\tremaining: 33.9s\n",
      "600:\tlearn: 2.8262693\ttotal: 48.6s\tremaining: 32.2s\n",
      "620:\tlearn: 2.7974037\ttotal: 50.4s\tremaining: 30.7s\n",
      "640:\tlearn: 2.7870400\ttotal: 51.8s\tremaining: 29s\n",
      "660:\tlearn: 2.7688957\ttotal: 53.4s\tremaining: 27.4s\n",
      "680:\tlearn: 2.7431591\ttotal: 55.4s\tremaining: 26s\n",
      "700:\tlearn: 2.7226032\ttotal: 57.6s\tremaining: 24.6s\n",
      "720:\tlearn: 2.7025983\ttotal: 60s\tremaining: 23.2s\n",
      "740:\tlearn: 2.6818528\ttotal: 1m 2s\tremaining: 21.7s\n",
      "760:\tlearn: 2.6597234\ttotal: 1m 4s\tremaining: 20.1s\n",
      "780:\tlearn: 2.6453615\ttotal: 1m 6s\tremaining: 18.5s\n",
      "800:\tlearn: 2.6346432\ttotal: 1m 8s\tremaining: 16.9s\n",
      "820:\tlearn: 2.6161179\ttotal: 1m 9s\tremaining: 15.2s\n",
      "840:\tlearn: 2.6018383\ttotal: 1m 11s\tremaining: 13.5s\n",
      "860:\tlearn: 2.5885943\ttotal: 1m 13s\tremaining: 11.8s\n",
      "880:\tlearn: 2.5804463\ttotal: 1m 15s\tremaining: 10.1s\n",
      "900:\tlearn: 2.5678463\ttotal: 1m 16s\tremaining: 8.43s\n",
      "920:\tlearn: 2.5553736\ttotal: 1m 18s\tremaining: 6.72s\n",
      "940:\tlearn: 2.5430274\ttotal: 1m 20s\tremaining: 5.03s\n",
      "960:\tlearn: 2.5263052\ttotal: 1m 21s\tremaining: 3.33s\n",
      "980:\tlearn: 2.5150776\ttotal: 1m 23s\tremaining: 1.62s\n",
      "999:\tlearn: 2.5056389\ttotal: 1m 25s\tremaining: 0us\n",
      "[12:13:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adeoluwa Adeboye\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\Adeoluwa Adeboye\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "# NOTE WE ONLY SUPPLIED ONE ARGUMENT...BECAUSE THE OTHER ARGUMENTS HAVE DEFAULT VALUES ATTACHED TO THEM\n",
    "output_csv(\"Stacking_Prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - THAT ALL FOR NOW\n",
    "## - FEEL FREE TO MAKE PULL REQUESTS, FORK, CLONE AND DOWNLOAD THIS REPO AND IMPROVE ON THIS MEAGRE MODEL OF MINE...vielen dank (THANK YOU!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
